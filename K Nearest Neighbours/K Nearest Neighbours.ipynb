{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c916657",
   "metadata": {},
   "source": [
    "<font color='red'> \n",
    "\n",
    "# We begin a new section now: Classification. In covering classification, we're going to cover two major classificiation algorithms: K Nearest Neighbors and the Support Vector Machine (SVM). While these two algorithms are both classification algorithms, they acheive results in different ways\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7b5b06",
   "metadata": {},
   "source": [
    "## To get the theory of classification and KNN visit this :\n",
    "https://pythonprogramming.net/k-nearest-neighbors-intro-machine-learning-tutorial/?completed=/sample-data-testing-machine-learning-tutorial/"
   ]
  },
  {
   "attachments": {
    "Screenshot%202022-06-01%20173127.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "980eabb7",
   "metadata": {},
   "source": [
    "![Screenshot%202022-06-01%20173127.png](attachment:Screenshot%202022-06-01%20173127.png)\n",
    "\n",
    "<font color='green'> \n",
    "\n",
    "\n",
    "## One more rule in this is that the K should not be equal to or less than the number of groups available\n",
    "\n",
    "## The explanation is simple, as in K nearest we take a point and try to find the K nearest neighbours i.e. if K=3 then we would like to find the 3 nearest neighbours, let them be black,red,black (in order of distance). So as black has 66% probability we will classify the point in the black category \n",
    "\n",
    "## But if K=1, we would not have any reliable data( suppose the nearest is red but suppose when we do it with K=3 then it comes red,black,black. So, if we do it K=3, the answer comes as red but with K=3 it comes as black which is accurate) \n",
    "\n",
    "## With K=2 we might have a split vote such as red,black which would have 50%,50% probability hence we need to assure that K nearest is never equal to or less than the number of voting groups\n",
    "</font>\n",
    "\n",
    "<font color='blue'> \n",
    "\n",
    "## Another thing is that K should always be odd , because even K many times lead to split vote even if K is higher than the voting groups, example would be red,black,red,red,black,black where both would have 50%,50% probability.\n",
    "\n",
    "## This would not be the case with odd as it being odd ensures that it's never evenly distributed\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c6fafe",
   "metadata": {},
   "source": [
    "## To exemplify classification, we're going to use a Breast Cancer Dataset, which is a dataset donated to the University of California, Irvine (UCI) collection from the University of Wisconsin-Madison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34cf01ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>unif_cell_size</th>\n",
       "      <th>unif_cell_shape</th>\n",
       "      <th>marg_adhesion</th>\n",
       "      <th>single_epith_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chrom</th>\n",
       "      <th>norm_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>776715</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>841769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>888820</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  clump_thickness  unif_cell_size  unif_cell_shape  marg_adhesion  \\\n",
       "0    1000025                5               1                1              1   \n",
       "1    1002945                5               4                4              5   \n",
       "2    1015425                3               1                1              1   \n",
       "3    1016277                6               8                8              1   \n",
       "4    1017023                4               1                1              3   \n",
       "..       ...              ...             ...              ...            ...   \n",
       "694   776715                3               1                1              1   \n",
       "695   841769                2               1                1              1   \n",
       "696   888820                5              10               10              3   \n",
       "697   897471                4               8                6              4   \n",
       "698   897471                4               8                8              5   \n",
       "\n",
       "     single_epith_cell_size bare_nuclei  bland_chrom  norm_nucleoli  mitoses  \\\n",
       "0                         2           1            3              1        1   \n",
       "1                         7          10            3              2        1   \n",
       "2                         2           2            3              1        1   \n",
       "3                         3           4            3              7        1   \n",
       "4                         2           1            3              1        1   \n",
       "..                      ...         ...          ...            ...      ...   \n",
       "694                       3           2            1              1        1   \n",
       "695                       2           1            1              1        1   \n",
       "696                       7           3            8             10        2   \n",
       "697                       3           4           10              6        1   \n",
       "698                       4           5           10              4        1   \n",
       "\n",
       "     class  \n",
       "0        2  \n",
       "1        2  \n",
       "2        2  \n",
       "3        2  \n",
       "4        2  \n",
       "..     ...  \n",
       "694      2  \n",
       "695      2  \n",
       "696      4  \n",
       "697      4  \n",
       "698      4  \n",
       "\n",
       "[699 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing, neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('breast-cancer-wisconsin.data')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f52ba5",
   "metadata": {},
   "source": [
    "## Missing/bad data: This dataset also has some missing data in it, which we're going to need to clean! Let's start off with our imports, pulling in the data, and some cleaning. After reading in the data, we take note that there are some columns with missing data. These columns have a \"?\" filled in. \n",
    "\n",
    "## In this case, we're choosing to fill in a -99,999 value for any missing data. You can choose how you want to handle missing data, but, in the real world, you may find that 50% or more of your rows contain missing data in one of the columns, especially if you are collecting data with extensive attributes. -99999 isn't perfect, but it works well enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0c90570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>unif_cell_size</th>\n",
       "      <th>unif_cell_shape</th>\n",
       "      <th>marg_adhesion</th>\n",
       "      <th>single_epith_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chrom</th>\n",
       "      <th>norm_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     clump_thickness  unif_cell_size  unif_cell_shape  marg_adhesion  \\\n",
       "0                  5               1                1              1   \n",
       "1                  5               4                4              5   \n",
       "2                  3               1                1              1   \n",
       "3                  6               8                8              1   \n",
       "4                  4               1                1              3   \n",
       "..               ...             ...              ...            ...   \n",
       "694                3               1                1              1   \n",
       "695                2               1                1              1   \n",
       "696                5              10               10              3   \n",
       "697                4               8                6              4   \n",
       "698                4               8                8              5   \n",
       "\n",
       "     single_epith_cell_size bare_nuclei  bland_chrom  norm_nucleoli  mitoses  \\\n",
       "0                         2           1            3              1        1   \n",
       "1                         7          10            3              2        1   \n",
       "2                         2           2            3              1        1   \n",
       "3                         3           4            3              7        1   \n",
       "4                         2           1            3              1        1   \n",
       "..                      ...         ...          ...            ...      ...   \n",
       "694                       3           2            1              1        1   \n",
       "695                       2           1            1              1        1   \n",
       "696                       7           3            8             10        2   \n",
       "697                       3           4           10              6        1   \n",
       "698                       4           5           10              4        1   \n",
       "\n",
       "     class  \n",
       "0        2  \n",
       "1        2  \n",
       "2        2  \n",
       "3        2  \n",
       "4        2  \n",
       "..     ...  \n",
       "694      2  \n",
       "695      2  \n",
       "696      4  \n",
       "697      4  \n",
       "698      4  \n",
       "\n",
       "[699 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace('?',-99999, inplace=True)\n",
    "df.drop(columns=['id'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01e51cb",
   "metadata": {},
   "source": [
    "## Now here the class is very important, if the class is 2  the cancer is 'benign'(not dangerous) and if it's 4 then it's 'malignant'(dangerous), we test our dataset accordingly with k nearest classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f54550db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9785714285714285\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing, neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('breast-cancer-wisconsin.data')\n",
    "df.replace('?',-99999, inplace=True)\n",
    "df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "X = np.array(df.drop(columns=['class']))\n",
    "y = np.array(df['class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94001eae",
   "metadata": {},
   "source": [
    "## The accuracy is very high but let's show what happens when we do indeed include truly meaningless and misleading data by commenting out the dropping of the id column which contains values like 1000025, 897471\tetc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f92d71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6071428571428571\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing, neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('breast-cancer-wisconsin.data')\n",
    "df.replace('?',-99999, inplace=True)\n",
    "#df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "X = np.array(df.drop(columns=['class']))\n",
    "y = np.array(df['class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804a43bc",
   "metadata": {},
   "source": [
    "## Now let us train our data with an example set created by ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "356aed75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9857142857142858\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing, neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('breast-cancer-wisconsin.data')\n",
    "df.replace('?',-99999, inplace=True)\n",
    "df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "X = np.array(df.drop(columns=['class']))\n",
    "y = np.array(df['class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "\n",
    "example_measures = np.array([4,2,1,1,1,2,3,2,1])\n",
    "example_measures = example_measures.reshape(1, -1)\n",
    "prediction = clf.predict(example_measures)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b12ed04",
   "metadata": {},
   "source": [
    "## Here if you do not reshape example_measures you will get a warning : DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
    "\n",
    "## So we need to reshape our data to a 2d array and as our data contains a sample data and not features( what it means is that a row would have values of all unif_cell_size, unif_cell_shape, marg_adhesion etc. whereas a column would have the valuesof only a single feature, and that is not the case with this example, it has data of every column except id(jo ki hamne pehle hi hata diya tha) and class(jisko predictkarna hai))\n",
    "\n",
    "## Look in this for why (-1,1) is used : https://stackoverflow.com/questions/18691084/what-does-1-mean-in-numpy-reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "204ca959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2]\n"
     ]
    }
   ],
   "source": [
    "example_measures = np.array([[4,2,1,1,1,2,3,2,1],[4,2,1,1,1,2,3,2,1]])\n",
    "example_measures = example_measures.reshape(2, -1)\n",
    "prediction = clf.predict(example_measures)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d10967",
   "metadata": {},
   "source": [
    "## If we had 2 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a107bb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2]\n"
     ]
    }
   ],
   "source": [
    "example_measures = np.array([[4,2,1,1,1,2,3,2,1],[4,2,1,1,1,2,3,2,1]])\n",
    "example_measures = example_measures.reshape(len(example_measures), -1)\n",
    "prediction = clf.predict(example_measures)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24145d4",
   "metadata": {},
   "source": [
    "## If we had more samples for that just use len function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfa45f3",
   "metadata": {},
   "source": [
    "<font color='green'> \n",
    "\n",
    "## Now, we have covered how to use the K Nearest Neighbors algorithm via Scikit-Learn to achieve 95% accuracy in predicting benign vs malignant tumors based on tumor attributes. Now, we're going to dig into how K Nearest Neighbors works so we have a full understanding of the algorithm itself, to better understand when it will and wont work for us\n",
    "</font>"
   ]
  },
  {
   "attachments": {
    "Screenshot%202022-06-01%20163628.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "ef392d2c",
   "metadata": {},
   "source": [
    "![Screenshot%202022-06-01%20163628.png](attachment:Screenshot%202022-06-01%20163628.png)\n",
    "\n",
    "## This is the formula to cover the distances where i represents the dimensions whether they be x,y,z etc. (the same as the formula sqrt((y2-y1)^2 + (x2-x1)^2) taught in school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9b08027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "plot1 = [1,3]\n",
    "plot2 = [2,5]\n",
    "euclidean_distance = sqrt( (plot1[0]-plot2[0])**2 + (plot1[1]-plot2[1])**2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d38a169",
   "metadata": {},
   "source": [
    "## This can be our formula for euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cb1af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import warnings\n",
    "from math import sqrt\n",
    "from collections import Counter\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "dataset = {'k':[[1,2],[2,3],[3,1]], 'r':[[6,5],[7,7],[8,6]]}\n",
    "new_features = [5,7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432062be",
   "metadata": {},
   "source": [
    "## The dataset is just a Python dictionary with the keys being the color of the points (think of these as the class), and then the datapoints that are attributed with this class\n",
    "## The second one will be the one we will be predict whether it will go with k or r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2b1a226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[[plt.scatter(ii[0],ii[1],s=100,color=i) for ii in dataset[i]] for i in dataset]\n",
    "plt.scatter(new_features[0], new_features[1], s=100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {
    "Screenshot%202022-06-01%20170923.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "eeec76c7",
   "metadata": {},
   "source": [
    "## The line that is [[plt.scatter(ii[0],ii[1],s=100,color=i) for ii in dataset[i]] for i in dataset] is the same as:\n",
    "\n",
    "![Screenshot%202022-06-01%20170923.png](attachment:Screenshot%202022-06-01%20170923.png)\n",
    "\n",
    "## You can see there are obvious groups of red and black, and then we have the blue dot. The blue dot is the new_features, which we're going to attempt to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba02218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbors(data, predict, k=3):\n",
    "    if len(data) >= k:\n",
    "        warnings.warn('K is set to a value less than total voting groups!')\n",
    "        \n",
    "    distances = []\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict))\n",
    "            distances.append([euclidean_distance,group])\n",
    "\n",
    "    votes = [i[1] for i in sorted(distances)[:k]]\n",
    "    vote_result = Counter(votes).most_common(1)[0][0]\n",
    "    return vote_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfc1d8c",
   "metadata": {},
   "source": [
    "## There's a skeleton of what we expect to have here to start. We want a function that will take in data to train against, new data to predict with, and a value for K, which we'll just set as defaulting to 3.\n",
    "\n",
    "## The distances would be a list of  euclidean distances i.e. the distances between the prediction point (5,7) and the points in the data (1,2) etc.\n",
    "\n",
    "## np.linalg.norm(np.array(features)-np.array(predict)) will be equal to :\n",
    "<font color='green'> \n",
    "\n",
    "## euclidean_distance = sqrt( (features[0]-predict[0])**2 + (features[1]-predict[1])**2 )\n",
    "## euclidean_distance = np.sqrt(np.sum((np.array(features)-np.array(predict))**2))\n",
    "</font>\n",
    "\n",
    "## So basically the euclidean distances\n",
    "\n",
    "##  votes = [i[1] for i in sorted(distances)[:k]] will sort the distances and give the index[1] i.e. the groups of the first K groups ([:K])\n",
    "\n",
    "## vote_result = Counter(votes).most_common(1)[0][0] will help us get the answer. A Counter is a dict subclass for counting hashable objects. It is a collection where elements are stored as dictionary keys and their counts are stored as dictionary values which will be like    \n",
    "## {'k' : [1] , 'r' : [2]} (an example)\n",
    "\n",
    "## most_common(n) returns a list of the n most common elements and their counts from the most common to the least. So here most_common(1) will give (['r',3]) and in [0][0] the first [0] will slect the first list in the tuple i.e. ['r',3] (socho) and the second one will give us the first element of the list i.e. 'r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b66fa453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.4031242374328485, 'k'], [5.0, 'k'], [6.324555320336759, 'k'], [2.23606797749979, 'r'], [2.0, 'r'], [3.1622776601683795, 'r']]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import warnings\n",
    "from math import sqrt\n",
    "from collections import Counter\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "def k_nearest_neighbors(data, predict, k=3):\n",
    "    if len(data) >= k:\n",
    "        warnings.warn('K is set to a value less than total voting groups!')\n",
    "        \n",
    "    distances = []\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict))\n",
    "            distances.append([euclidean_distance,group])\n",
    "    \n",
    "    print(distances)\n",
    "    \n",
    "    votes = [i[1] for i in sorted(distances)[:k]]\n",
    "    vote_result = Counter(votes).most_common(1)[0][0]\n",
    "    return vote_result\n",
    "\n",
    "dataset = {'k':[[1,2],[2,3],[3,1]], 'r':[[6,5],[7,7],[8,6]]}\n",
    "new_features = [5,7]\n",
    "[[plt.scatter(ii[0],ii[1],s=100,color=i) for ii in dataset[i]] for i in dataset]\n",
    "# same as:\n",
    "##for i in dataset:\n",
    "##    for ii in dataset[i]:\n",
    "##        plt.scatter(ii[0],ii[1],s=100,color=i)\n",
    "        \n",
    "plt.scatter(new_features[0], new_features[1], s=100)\n",
    "\n",
    "result = k_nearest_neighbors(dataset, new_features)\n",
    "plt.scatter(new_features[0], new_features[1], s=100, color = result)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9f2359",
   "metadata": {},
   "source": [
    "## Here I have printed the distances just for understanding of the previous point.\n",
    "\n",
    "## Now we can see that the point that was blue at first is now classified with the red group.Things have worked on a small scale, but how will we do on the breast cancer dataset? How will we compare to Scikit-Learn's rendition of K Nearest Neighbors? In the next tutorial, we'll apply our algorithm to that dataset to find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d8624cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9568345323741008\n",
      "\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "\n",
      "df before <full_data = df.astype(float).values.tolist() :> \n",
      "\n",
      "    clump_thickness  unif_cell_size  unif_cell_shape  marg_adhesion  \\\n",
      "20                7               3                2             10   \n",
      "21               10               5                5              3   \n",
      "22                3               1                1              1   \n",
      "23                8               4                5              1   \n",
      "24                1               1                1              1   \n",
      "25                5               2                3              4   \n",
      "26                3               2                1              1   \n",
      "27                5               1                1              1   \n",
      "28                2               1                1              1   \n",
      "29                1               1                3              1   \n",
      "30                3               1                1              1   \n",
      "31                2               1                1              1   \n",
      "32               10               7                7              3   \n",
      "33                2               1                1              2   \n",
      "34                3               1                2              1   \n",
      "35                2               1                1              1   \n",
      "36               10              10               10              8   \n",
      "37                6               2                1              1   \n",
      "38                5               4                4              9   \n",
      "39                2               5                3              3   \n",
      "40                6               6                6              9   \n",
      "41               10               4                3              1   \n",
      "42                6              10               10              2   \n",
      "43                5               6                5              6   \n",
      "44               10              10               10              4   \n",
      "\n",
      "    single_epith_cell_size bare_nuclei  bland_chrom  norm_nucleoli  mitoses  \\\n",
      "20                       5          10            5              4        4   \n",
      "21                       6           7            7             10        1   \n",
      "22                       2           1            2              1        1   \n",
      "23                       2      -99999            7              3        1   \n",
      "24                       2           1            3              1        1   \n",
      "25                       2           7            3              6        1   \n",
      "26                       1           1            2              1        1   \n",
      "27                       2           1            2              1        1   \n",
      "28                       2           1            2              1        1   \n",
      "29                       2           1            1              1        1   \n",
      "30                       1           1            2              1        1   \n",
      "31                       2           1            3              1        1   \n",
      "32                       8           5            7              4        3   \n",
      "33                       2           1            3              1        1   \n",
      "34                       2           1            2              1        1   \n",
      "35                       2           1            2              1        1   \n",
      "36                       6           1            8              9        1   \n",
      "37                       1           1            7              1        1   \n",
      "38                       2          10            5              6        1   \n",
      "39                       6           7            7              5        1   \n",
      "40                       6      -99999            7              8        1   \n",
      "41                       3           3            6              5        2   \n",
      "42                       8          10            7              3        3   \n",
      "43                      10           1            3              1        1   \n",
      "44                       8           1            8             10        1   \n",
      "\n",
      "    class  \n",
      "20      4  \n",
      "21      4  \n",
      "22      2  \n",
      "23      4  \n",
      "24      2  \n",
      "25      4  \n",
      "26      2  \n",
      "27      2  \n",
      "28      2  \n",
      "29      2  \n",
      "30      2  \n",
      "31      2  \n",
      "32      4  \n",
      "33      2  \n",
      "34      2  \n",
      "35      2  \n",
      "36      4  \n",
      "37      2  \n",
      "38      4  \n",
      "39      4  \n",
      "40      2  \n",
      "41      4  \n",
      "42      4  \n",
      "43      4  \n",
      "44      4  \n",
      "\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "\n",
      "df after <full_data = df.astype(float).values.tolist() :>\n",
      "\n",
      "[[3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0], [8.0, 8.0, 9.0, 6.0, 6.0, 3.0, 10.0, 10.0, 1.0, 4.0], [8.0, 10.0, 10.0, 10.0, 5.0, 10.0, 8.0, 10.0, 6.0, 4.0], [10.0, 10.0, 9.0, 3.0, 7.0, 5.0, 3.0, 5.0, 1.0, 4.0]]\n",
      "\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "\n",
      "Train_data :\n",
      "\n",
      "[[3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0], [8.0, 8.0, 9.0, 6.0, 6.0, 3.0, 10.0, 10.0, 1.0, 4.0], [8.0, 10.0, 10.0, 10.0, 5.0, 10.0, 8.0, 10.0, 6.0, 4.0], [10.0, 10.0, 9.0, 3.0, 7.0, 5.0, 3.0, 5.0, 1.0, 4.0]]\n",
      "\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "\n",
      "Train_set :\n",
      "\n",
      "{2: [[3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 2.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, -99999.0, 1.0, 1.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, -99999.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0], [5.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0], [4.0, 3.0, 1.0, 1.0, 2.0, 1.0, 4.0, 8.0, 1.0], [5.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [4.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, -99999.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 3.0, 8.0, 1.0, 5.0, 8.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0], [3.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 1.0, 4.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0], [1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0], [5.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 8.0], [5.0, 1.0, 1.0, 4.0, 2.0, 1.0, 3.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0], [5.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0], [1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0], [4.0, 4.0, 2.0, 1.0, 2.0, 5.0, 2.0, 1.0, 2.0], [5.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 2.0, 2.0, 4.0, 2.0, 4.0, 1.0, 1.0, 1.0], [5.0, 3.0, 6.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [4.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 5.0, 1.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 5.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0], [4.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [5.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [5.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0], [2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [5.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0], [5.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0], [6.0, 3.0, 3.0, 3.0, 3.0, 2.0, 6.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0], [1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0], [3.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 6.0, 1.0], [5.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0], [8.0, 4.0, 4.0, 5.0, 4.0, 7.0, 7.0, 8.0, 2.0], [3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0], [4.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 5.0, 5.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 1.0, 3.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0], [1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 1.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [6.0, 8.0, 8.0, 1.0, 3.0, 4.0, 3.0, 7.0, 1.0], [1.0, 1.0, 2.0, 1.0, 3.0, -99999.0, 1.0, 1.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [5.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [5.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 5.0, 1.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [4.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [6.0, 9.0, 7.0, 5.0, 5.0, 8.0, 4.0, 2.0, 1.0], [3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 1.0], [5.0, 2.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [4.0, 4.0, 4.0, 4.0, 6.0, 5.0, 7.0, 3.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 3.0, 2.0, 1.0, 3.0, 1.0, 3.0, 6.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [7.0, 1.0, 2.0, 3.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [6.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 5.0, 1.0, 1.0, 1.0], [1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 5.0, 3.0, 2.0], [1.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0], [4.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [6.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 5.0, 5.0, 1.0, 1.0], [4.0, 1.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0], [2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0], [4.0, 1.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0], [3.0, 2.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [4.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [3.0, 1.0, 3.0, 1.0, 2.0, -99999.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 1.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [4.0, 6.0, 5.0, 6.0, 7.0, -99999.0, 4.0, 9.0, 1.0], [4.0, 4.0, 4.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [5.0, 4.0, 4.0, 5.0, 7.0, 10.0, 3.0, 2.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 7.0, 2.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [4.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0], [4.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [4.0, 2.0, 4.0, 3.0, 2.0, 2.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 7.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 4.0, 3.0, 1.0, 2.0, -99999.0, 2.0, 3.0, 1.0], [4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 3.0, 2.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0], [4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [4.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [6.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0], [6.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [6.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [3.0, 1.0, 1.0, 2.0, 3.0, 4.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [5.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 3.0, 2.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0], [3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [3.0, 4.0, 5.0, 3.0, 7.0, 3.0, 4.0, 6.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0], [1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 10.0, 3.0, 1.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0], [8.0, 4.0, 6.0, 3.0, 3.0, 1.0, 4.0, 3.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [6.0, 2.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0], [1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 7.0, 7.0, 1.0, 5.0, 8.0, 3.0, 4.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0], [2.0, 3.0, 1.0, 1.0, 5.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [3.0, 1.0, 1.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0], [5.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 4.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [5.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0], [5.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 2.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [5.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [5.0, 3.0, 4.0, 1.0, 4.0, 1.0, 3.0, 1.0, 1.0], [5.0, 1.0, 2.0, 10.0, 4.0, 5.0, 2.0, 1.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0], [3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [4.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [5.0, 4.0, 5.0, 1.0, 8.0, 1.0, 3.0, 6.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, -99999.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0], [4.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [6.0, 6.0, 6.0, 9.0, 6.0, -99999.0, 7.0, 8.0, 1.0], [5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [6.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0], [2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0], [3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0], [3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0], [5.0, 3.0, 4.0, 3.0, 4.0, 5.0, 4.0, 7.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]], 4: [[8.0, 8.0, 9.0, 6.0, 6.0, 3.0, 10.0, 10.0, 1.0], [8.0, 10.0, 10.0, 10.0, 5.0, 10.0, 8.0, 10.0, 6.0], [10.0, 10.0, 9.0, 3.0, 7.0, 5.0, 3.0, 5.0, 1.0], [10.0, 10.0, 10.0, 10.0, 5.0, 10.0, 10.0, 10.0, 7.0], [6.0, 10.0, 10.0, 10.0, 4.0, 10.0, 7.0, 10.0, 1.0], [3.0, 10.0, 7.0, 8.0, 5.0, 8.0, 7.0, 4.0, 1.0], [8.0, 6.0, 5.0, 4.0, 3.0, 10.0, 6.0, 1.0, 1.0], [10.0, 4.0, 3.0, 2.0, 3.0, 10.0, 5.0, 3.0, 2.0], [5.0, 3.0, 4.0, 1.0, 8.0, 10.0, 4.0, 9.0, 1.0], [2.0, 7.0, 10.0, 10.0, 7.0, 10.0, 4.0, 9.0, 4.0], [4.0, 10.0, 4.0, 7.0, 3.0, 10.0, 9.0, 10.0, 1.0], [10.0, 7.0, 7.0, 3.0, 8.0, 5.0, 7.0, 4.0, 3.0], [3.0, 6.0, 4.0, 10.0, 3.0, 3.0, 3.0, 4.0, 1.0], [10.0, 10.0, 7.0, 8.0, 7.0, 1.0, 10.0, 10.0, 3.0], [10.0, 4.0, 6.0, 1.0, 2.0, 10.0, 5.0, 3.0, 1.0], [8.0, 6.0, 7.0, 3.0, 3.0, 10.0, 3.0, 4.0, 2.0], [8.0, 4.0, 4.0, 1.0, 2.0, 9.0, 3.0, 3.0, 1.0], [4.0, 5.0, 5.0, 10.0, 4.0, 10.0, 7.0, 5.0, 8.0], [7.0, 8.0, 7.0, 6.0, 4.0, 3.0, 8.0, 8.0, 4.0], [8.0, 5.0, 5.0, 5.0, 2.0, 10.0, 4.0, 3.0, 1.0], [6.0, 10.0, 10.0, 2.0, 8.0, 10.0, 7.0, 3.0, 3.0], [5.0, 4.0, 6.0, 6.0, 4.0, 10.0, 4.0, 3.0, 1.0], [8.0, 7.0, 6.0, 4.0, 4.0, 10.0, 5.0, 1.0, 1.0], [10.0, 5.0, 8.0, 10.0, 3.0, 10.0, 5.0, 1.0, 3.0], [9.0, 10.0, 10.0, 10.0, 10.0, 5.0, 10.0, 10.0, 10.0], [5.0, 3.0, 3.0, 3.0, 6.0, 10.0, 3.0, 1.0, 1.0], [8.0, 7.0, 8.0, 5.0, 10.0, 10.0, 7.0, 2.0, 1.0], [10.0, 3.0, 3.0, 1.0, 2.0, 10.0, 7.0, 6.0, 1.0], [8.0, 7.0, 8.0, 7.0, 5.0, 5.0, 5.0, 10.0, 2.0], [10.0, 4.0, 4.0, 6.0, 2.0, 10.0, 2.0, 3.0, 1.0], [10.0, 3.0, 6.0, 2.0, 3.0, 5.0, 4.0, 10.0, 2.0], [7.0, 5.0, 3.0, 7.0, 4.0, 10.0, 7.0, 5.0, 5.0], [8.0, 6.0, 4.0, 10.0, 10.0, 1.0, 3.0, 5.0, 1.0], [4.0, 8.0, 7.0, 10.0, 4.0, 10.0, 7.0, 5.0, 1.0], [5.0, 3.0, 3.0, 4.0, 2.0, 4.0, 3.0, 4.0, 1.0], [5.0, 6.0, 6.0, 8.0, 6.0, 10.0, 4.0, 10.0, 4.0], [9.0, 8.0, 8.0, 9.0, 6.0, 3.0, 4.0, 1.0, 1.0], [8.0, 3.0, 8.0, 3.0, 4.0, 9.0, 8.0, 9.0, 8.0], [9.0, 1.0, 2.0, 6.0, 4.0, 10.0, 7.0, 7.0, 2.0], [8.0, 2.0, 4.0, 1.0, 5.0, 1.0, 5.0, 4.0, 4.0], [10.0, 10.0, 10.0, 8.0, 6.0, 1.0, 8.0, 9.0, 1.0], [5.0, 8.0, 9.0, 4.0, 3.0, 10.0, 7.0, 1.0, 1.0], [10.0, 10.0, 10.0, 7.0, 9.0, 10.0, 7.0, 10.0, 10.0], [10.0, 4.0, 4.0, 10.0, 2.0, 10.0, 5.0, 3.0, 3.0], [10.0, 10.0, 10.0, 10.0, 3.0, 10.0, 10.0, 6.0, 1.0], [10.0, 10.0, 10.0, 8.0, 2.0, 10.0, 4.0, 1.0, 1.0], [8.0, 5.0, 6.0, 2.0, 3.0, 10.0, 6.0, 6.0, 1.0], [8.0, 10.0, 5.0, 3.0, 8.0, 4.0, 4.0, 10.0, 3.0], [10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 4.0, 10.0, 10.0], [8.0, 10.0, 10.0, 1.0, 3.0, 6.0, 3.0, 9.0, 1.0], [5.0, 10.0, 10.0, 3.0, 7.0, 3.0, 8.0, 10.0, 2.0], [6.0, 3.0, 4.0, 1.0, 5.0, 2.0, 3.0, 9.0, 1.0], [10.0, 6.0, 4.0, 1.0, 3.0, 4.0, 3.0, 2.0, 3.0], [2.0, 5.0, 3.0, 3.0, 6.0, 7.0, 7.0, 5.0, 1.0], [10.0, 8.0, 10.0, 1.0, 3.0, 10.0, 5.0, 1.0, 1.0], [10.0, 4.0, 3.0, 1.0, 3.0, 3.0, 6.0, 5.0, 2.0], [5.0, 5.0, 5.0, 8.0, 10.0, 8.0, 7.0, 3.0, 7.0], [4.0, 5.0, 5.0, 8.0, 6.0, 10.0, 10.0, 7.0, 1.0], [10.0, 10.0, 10.0, 3.0, 10.0, 8.0, 8.0, 1.0, 1.0], [8.0, 3.0, 4.0, 9.0, 3.0, 10.0, 3.0, 3.0, 1.0], [8.0, 4.0, 10.0, 5.0, 4.0, 4.0, 7.0, 10.0, 1.0], [3.0, 10.0, 3.0, 10.0, 6.0, 10.0, 5.0, 1.0, 4.0], [7.0, 4.0, 7.0, 4.0, 3.0, 7.0, 7.0, 6.0, 1.0], [10.0, 3.0, 4.0, 5.0, 3.0, 10.0, 4.0, 1.0, 1.0], [9.0, 5.0, 8.0, 1.0, 2.0, 3.0, 2.0, 1.0, 5.0], [5.0, 10.0, 10.0, 10.0, 10.0, 2.0, 10.0, 10.0, 10.0], [1.0, 4.0, 3.0, 10.0, 4.0, 10.0, 5.0, 6.0, 1.0], [6.0, 5.0, 4.0, 4.0, 3.0, 9.0, 7.0, 8.0, 3.0], [5.0, 6.0, 7.0, 8.0, 8.0, 10.0, 3.0, 10.0, 3.0], [7.0, 6.0, 3.0, 2.0, 5.0, 10.0, 7.0, 4.0, 6.0], [4.0, 6.0, 6.0, 5.0, 7.0, 6.0, 7.0, 7.0, 3.0], [8.0, 10.0, 10.0, 10.0, 7.0, 5.0, 4.0, 8.0, 7.0], [8.0, 4.0, 4.0, 1.0, 6.0, 10.0, 2.0, 5.0, 2.0], [1.0, 5.0, 8.0, 6.0, 5.0, 8.0, 7.0, 10.0, 1.0], [10.0, 4.0, 3.0, 10.0, 3.0, 10.0, 7.0, 1.0, 2.0], [3.0, 3.0, 6.0, 4.0, 5.0, 8.0, 4.0, 4.0, 1.0], [8.0, 10.0, 10.0, 7.0, 10.0, 10.0, 7.0, 3.0, 8.0], [10.0, 10.0, 8.0, 6.0, 4.0, 5.0, 8.0, 10.0, 1.0], [3.0, 4.0, 5.0, 2.0, 6.0, 8.0, 4.0, 1.0, 1.0], [5.0, 10.0, 10.0, 9.0, 6.0, 10.0, 7.0, 10.0, 5.0], [10.0, 7.0, 7.0, 4.0, 5.0, 10.0, 5.0, 7.0, 2.0], [10.0, 10.0, 8.0, 10.0, 6.0, 5.0, 10.0, 3.0, 1.0], [5.0, 3.0, 5.0, 5.0, 3.0, 3.0, 4.0, 10.0, 1.0], [2.0, 3.0, 4.0, 4.0, 2.0, 5.0, 2.0, 5.0, 1.0], [9.0, 5.0, 5.0, 2.0, 2.0, 2.0, 5.0, 1.0, 1.0], [8.0, 7.0, 5.0, 10.0, 7.0, 9.0, 5.0, 5.0, 4.0], [9.0, 10.0, 10.0, 1.0, 10.0, 8.0, 3.0, 3.0, 1.0], [9.0, 10.0, 10.0, 1.0, 10.0, 8.0, 3.0, 3.0, 1.0], [9.0, 6.0, 9.0, 2.0, 10.0, 6.0, 2.0, 9.0, 10.0], [8.0, 3.0, 5.0, 4.0, 5.0, 10.0, 1.0, 6.0, 2.0], [10.0, 5.0, 7.0, 4.0, 4.0, 10.0, 8.0, 9.0, 1.0], [7.0, 6.0, 4.0, 8.0, 10.0, 10.0, 9.0, 5.0, 3.0], [10.0, 3.0, 5.0, 4.0, 3.0, 7.0, 3.0, 5.0, 3.0], [4.0, 1.0, 1.0, 3.0, 1.0, 5.0, 2.0, 1.0, 1.0], [8.0, 7.0, 8.0, 5.0, 5.0, 10.0, 9.0, 10.0, 1.0], [10.0, 5.0, 5.0, 6.0, 8.0, 8.0, 7.0, 1.0, 1.0], [8.0, 8.0, 9.0, 4.0, 5.0, 10.0, 7.0, 8.0, 1.0], [10.0, 10.0, 10.0, 2.0, 10.0, 10.0, 5.0, 3.0, 3.0], [10.0, 6.0, 3.0, 6.0, 4.0, 10.0, 7.0, 8.0, 4.0], [7.0, 6.0, 10.0, 5.0, 3.0, 10.0, 9.0, 10.0, 2.0], [3.0, 6.0, 6.0, 6.0, 5.0, 10.0, 6.0, 8.0, 3.0], [3.0, 4.0, 4.0, 10.0, 5.0, 1.0, 3.0, 3.0, 1.0], [10.0, 4.0, 5.0, 4.0, 3.0, 5.0, 7.0, 3.0, 1.0], [7.0, 2.0, 4.0, 1.0, 6.0, 10.0, 5.0, 4.0, 3.0], [2.0, 5.0, 7.0, 6.0, 4.0, 10.0, 7.0, 6.0, 1.0], [10.0, 8.0, 8.0, 2.0, 3.0, 4.0, 8.0, 7.0, 8.0], [10.0, 1.0, 1.0, 1.0, 2.0, 10.0, 5.0, 4.0, 1.0], [8.0, 10.0, 8.0, 8.0, 4.0, 8.0, 7.0, 7.0, 1.0], [10.0, 10.0, 10.0, 10.0, 10.0, 1.0, 8.0, 8.0, 8.0], [6.0, 6.0, 6.0, 5.0, 4.0, 10.0, 7.0, 6.0, 2.0], [7.0, 5.0, 6.0, 10.0, 5.0, 10.0, 7.0, 9.0, 4.0], [3.0, 7.0, 7.0, 4.0, 4.0, 9.0, 4.0, 8.0, 1.0], [5.0, 8.0, 4.0, 10.0, 5.0, 8.0, 9.0, 10.0, 1.0], [10.0, 8.0, 8.0, 2.0, 8.0, 10.0, 4.0, 8.0, 10.0], [10.0, 5.0, 10.0, 3.0, 5.0, 8.0, 7.0, 8.0, 3.0], [10.0, 6.0, 5.0, 8.0, 5.0, 10.0, 8.0, 6.0, 1.0], [8.0, 8.0, 7.0, 4.0, 10.0, 10.0, 7.0, 8.0, 7.0], [5.0, 10.0, 10.0, 10.0, 4.0, 10.0, 5.0, 6.0, 3.0], [10.0, 5.0, 5.0, 3.0, 6.0, 7.0, 7.0, 10.0, 1.0], [4.0, 8.0, 8.0, 5.0, 4.0, 5.0, 10.0, 4.0, 1.0], [10.0, 6.0, 6.0, 3.0, 4.0, 5.0, 3.0, 6.0, 1.0], [10.0, 4.0, 5.0, 5.0, 5.0, 10.0, 4.0, 1.0, 1.0], [5.0, 2.0, 3.0, 4.0, 2.0, 7.0, 3.0, 6.0, 1.0], [8.0, 7.0, 4.0, 4.0, 5.0, 3.0, 5.0, 10.0, 1.0], [7.0, 9.0, 4.0, 10.0, 10.0, 3.0, 5.0, 3.0, 3.0], [5.0, 7.0, 10.0, 10.0, 5.0, 10.0, 10.0, 10.0, 1.0], [5.0, 5.0, 5.0, 6.0, 3.0, 10.0, 3.0, 1.0, 1.0], [10.0, 8.0, 8.0, 4.0, 10.0, 10.0, 8.0, 1.0, 1.0], [8.0, 4.0, 7.0, 1.0, 3.0, 10.0, 3.0, 9.0, 2.0], [5.0, 10.0, 10.0, 3.0, 8.0, 1.0, 5.0, 10.0, 3.0], [8.0, 10.0, 10.0, 8.0, 5.0, 10.0, 7.0, 8.0, 1.0], [10.0, 4.0, 6.0, 4.0, 5.0, 10.0, 7.0, 1.0, 1.0], [6.0, 6.0, 7.0, 10.0, 3.0, 10.0, 8.0, 10.0, 2.0], [8.0, 7.0, 8.0, 2.0, 4.0, 2.0, 5.0, 10.0, 1.0], [7.0, 5.0, 10.0, 10.0, 10.0, 10.0, 4.0, 10.0, 3.0], [9.0, 9.0, 10.0, 3.0, 6.0, 10.0, 7.0, 10.0, 6.0], [7.0, 8.0, 7.0, 2.0, 4.0, 8.0, 3.0, 8.0, 2.0], [5.0, 3.0, 2.0, 8.0, 5.0, 10.0, 8.0, 1.0, 2.0], [8.0, 10.0, 10.0, 10.0, 6.0, 10.0, 10.0, 10.0, 10.0], [10.0, 4.0, 7.0, 2.0, 2.0, 8.0, 6.0, 1.0, 1.0], [5.0, 4.0, 4.0, 9.0, 2.0, 10.0, 5.0, 6.0, 1.0], [10.0, 3.0, 5.0, 1.0, 10.0, 5.0, 3.0, 10.0, 2.0], [5.0, 7.0, 9.0, 8.0, 6.0, 10.0, 8.0, 10.0, 1.0], [3.0, 10.0, 8.0, 7.0, 6.0, 9.0, 9.0, 3.0, 8.0], [6.0, 10.0, 7.0, 7.0, 6.0, 4.0, 8.0, 10.0, 2.0], [5.0, 4.0, 6.0, 10.0, 2.0, 10.0, 4.0, 1.0, 1.0], [10.0, 8.0, 4.0, 4.0, 4.0, 10.0, 3.0, 10.0, 4.0], [5.0, 2.0, 3.0, 1.0, 6.0, 10.0, 5.0, 1.0, 1.0], [10.0, 7.0, 7.0, 6.0, 4.0, 10.0, 4.0, 1.0, 2.0], [6.0, 3.0, 2.0, 1.0, 3.0, 4.0, 4.0, 1.0, 1.0], [10.0, 4.0, 4.0, 10.0, 6.0, 10.0, 5.0, 5.0, 1.0], [5.0, 6.0, 6.0, 2.0, 4.0, 10.0, 3.0, 6.0, 1.0], [7.0, 5.0, 6.0, 3.0, 3.0, 8.0, 7.0, 4.0, 1.0], [5.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0], [7.0, 5.0, 6.0, 10.0, 4.0, 10.0, 5.0, 3.0, 1.0], [5.0, 5.0, 7.0, 8.0, 6.0, 10.0, 7.0, 4.0, 1.0], [3.0, 3.0, 5.0, 2.0, 3.0, 10.0, 7.0, 1.0, 1.0], [9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 1.0], [10.0, 4.0, 2.0, 1.0, 3.0, 2.0, 4.0, 3.0, 10.0], [7.0, 6.0, 6.0, 3.0, 2.0, 10.0, 7.0, 1.0, 1.0], [10.0, 6.0, 6.0, 2.0, 4.0, 10.0, 9.0, 7.0, 1.0], [7.0, 3.0, 2.0, 10.0, 5.0, 10.0, 5.0, 4.0, 4.0], [6.0, 5.0, 5.0, 8.0, 4.0, 10.0, 3.0, 4.0, 1.0], [7.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0, 2.0, 7.0], [4.0, 8.0, 6.0, 4.0, 3.0, 4.0, 10.0, 6.0, 1.0], [5.0, 4.0, 6.0, 7.0, 9.0, 7.0, 8.0, 10.0, 1.0], [5.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 1.0, 1.0], [10.0, 5.0, 7.0, 3.0, 3.0, 7.0, 3.0, 3.0, 8.0], [10.0, 10.0, 10.0, 6.0, 8.0, 4.0, 8.0, 5.0, 1.0], [6.0, 10.0, 10.0, 2.0, 8.0, 10.0, 7.0, 3.0, 3.0], [6.0, 10.0, 2.0, 8.0, 10.0, 2.0, 7.0, 8.0, 10.0], [5.0, 8.0, 7.0, 7.0, 10.0, 10.0, 5.0, 7.0, 1.0], [5.0, 10.0, 8.0, 10.0, 8.0, 10.0, 3.0, 6.0, 3.0], [5.0, 7.0, 10.0, 6.0, 5.0, 10.0, 7.0, 5.0, 1.0], [5.0, 6.0, 5.0, 6.0, 10.0, 1.0, 3.0, 1.0, 1.0], [4.0, 2.0, 3.0, 5.0, 3.0, 8.0, 7.0, 6.0, 1.0], [8.0, 10.0, 10.0, 8.0, 7.0, 10.0, 9.0, 7.0, 1.0], [10.0, 10.0, 10.0, 4.0, 8.0, 1.0, 8.0, 10.0, 1.0], [10.0, 10.0, 10.0, 7.0, 10.0, 10.0, 8.0, 2.0, 1.0], [10.0, 8.0, 7.0, 4.0, 3.0, 10.0, 7.0, 9.0, 1.0], [8.0, 10.0, 10.0, 10.0, 6.0, 10.0, 10.0, 10.0, 1.0], [6.0, 8.0, 7.0, 8.0, 6.0, 8.0, 8.0, 9.0, 1.0], [1.0, 6.0, 8.0, 10.0, 8.0, 10.0, 5.0, 7.0, 1.0], [10.0, 8.0, 10.0, 10.0, 6.0, 1.0, 3.0, 1.0, 10.0], [7.0, 4.0, 4.0, 3.0, 4.0, 10.0, 6.0, 9.0, 1.0], [8.0, 10.0, 10.0, 8.0, 6.0, 9.0, 3.0, 10.0, 10.0], [10.0, 10.0, 10.0, 8.0, 6.0, 8.0, 7.0, 10.0, 1.0], [10.0, 10.0, 10.0, 10.0, 7.0, 10.0, 7.0, 10.0, 4.0], [5.0, 10.0, 10.0, 8.0, 5.0, 5.0, 7.0, 10.0, 1.0], [6.0, 10.0, 5.0, 5.0, 4.0, 10.0, 6.0, 10.0, 1.0], [10.0, 5.0, 5.0, 6.0, 3.0, 10.0, 7.0, 9.0, 2.0], [8.0, 6.0, 4.0, 3.0, 5.0, 9.0, 3.0, 1.0, 1.0]]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import warnings\n",
    "from collections import Counter\n",
    "#dont forget this\n",
    "import pandas as pd\n",
    "import random\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "def k_nearest_neighbors(data, predict, k=3):\n",
    "    if len(data) >= k:\n",
    "        warnings.warn('K is set to a value less than total voting groups!')\n",
    "    distances = []\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict))\n",
    "            distances.append([euclidean_distance,group])\n",
    "    votes = [i[1] for i in sorted(distances)[:k]]\n",
    "    vote_result = Counter(votes).most_common(1)[0][0]\n",
    "    return vote_result\n",
    "\n",
    "df = pd.read_csv('breast-cancer-wisconsin.data')\n",
    "df.replace('?',-99999, inplace=True)\n",
    "df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "\n",
    "full_data = df.astype(float).values.tolist()\n",
    "random.shuffle(full_data)\n",
    "\n",
    "test_size = 0.2\n",
    "train_set = {2:[], 4:[]}\n",
    "test_set = {2:[], 4:[]}\n",
    "train_data = full_data[:-int(test_size*len(full_data))]\n",
    "test_data = full_data[-int(test_size*len(full_data)):]\n",
    "\n",
    "\n",
    "\n",
    "for i in train_data:\n",
    "    train_set[i[-1]].append(i[:-1])\n",
    "\n",
    "    \n",
    "for i in test_data:\n",
    "    test_set[i[-1]].append(i[:-1])\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for group in test_set:\n",
    "    for data in test_set[group]:\n",
    "        vote = k_nearest_neighbors(train_set, data, k=5)\n",
    "        if group == vote:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "print('Accuracy:', correct/total)\n",
    "print(2*\"\\n\")\n",
    "print(100*\"#\")\n",
    "print(2*\"\\n\")\n",
    "print(\"df before <full_data = df.astype(float).values.tolist() :> \\n\")\n",
    "print(df.iloc[20:45])\n",
    "print(2*\"\\n\")\n",
    "print(100*\"#\")\n",
    "print(2*\"\\n\")\n",
    "print(\"df after <full_data = df.astype(float).values.tolist() :>\\n\")\n",
    "print(full_data[:5])\n",
    "print(2*\"\\n\")\n",
    "print(100*\"#\")\n",
    "print(2*\"\\n\")\n",
    "print(\"Train_data :\\n\")\n",
    "print(train_data[:5])\n",
    "print(2*\"\\n\")\n",
    "print(100*\"#\")\n",
    "print(2*\"\\n\")\n",
    "print(\"Train_set :\\n\")\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b4dc62",
   "metadata": {},
   "source": [
    "<font color=\"red\">\n",
    "\n",
    "# The above results are for understanding, look at them to understand the points below \n",
    "</font>\n",
    "\n",
    "## Here we write full_data = df.astype(float).values.tolist() as many of the data in the dataset is in strings like '1' for some or the other reason. So we convert all the data to float and return a list of lists\n",
    "<font color=\"green\">\n",
    "\n",
    "## Important : We do not need to write full_data = random.shuffle(full_data) to shuffle full_data, even just writing random.shuffle(full_data) would shuffle it\n",
    "</font>\n",
    "\n",
    "## After shuffling the data we prepare the dictionaries for the training and testing set to be populated. Next, we specify which chunk is the train_data and which is the test_data. We do this by selecting the first 80% as train_data (by doing logic that says to slice the list up to the last 20%), and then we create the test_data by slicing the final 20% of the shuffled data\n",
    "\n",
    "<font color=\"blue\">\n",
    "    \n",
    "## Then in \" for i in train_data: train_set[i[-1]].append(i[:-1]) \". What we are doing here is that first in \"for i in train_data\" we are selecting each list(see in the printed version of train_data) and for each list i.e \"i\" we do i[-1] i.e. selecting the last feature (class) which is either 2 or 4. By this we can pass the data of classes 2 or 4 in their respective dictionaries.\n",
    "\n",
    "## Then we append the rest of the data i[:-1] to the dictionary hence creating a dictionary of classes 2 and 4 with their respective features\n",
    "</font> \n",
    "\n",
    "## In the last section,in \"for group in test_set:\" the groups will be '2' and '4'\n",
    "\n",
    "## In for \"for data in test_set[group]:\" , it will give the various lists of data in the '2' group first and then the '4' group. Then we will compare our classificationmodel with theScikit Learn KNeighborsClassifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10d3b2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9856115107913669\n",
      "CPU times: total: 1.08 s\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import warnings\n",
    "from collections import Counter\n",
    "#dont forget this\n",
    "import pandas as pd\n",
    "import random\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "def k_nearest_neighbors(data, predict, k=3):\n",
    "    if len(data) >= k:\n",
    "        warnings.warn('K is set to a value less than total voting groups!')\n",
    "    distances = []\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict))\n",
    "            distances.append([euclidean_distance,group])\n",
    "    votes = [i[1] for i in sorted(distances)[:k]]\n",
    "    vote_result = Counter(votes).most_common(1)[0][0]\n",
    "    return vote_result\n",
    "\n",
    "df = pd.read_csv('breast-cancer-wisconsin.data')\n",
    "df.replace('?',-99999, inplace=True)\n",
    "df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "\n",
    "full_data = df.astype(float).values.tolist()\n",
    "random.shuffle(full_data)\n",
    "\n",
    "test_size = 0.2\n",
    "train_set = {2:[], 4:[]}\n",
    "test_set = {2:[], 4:[]}\n",
    "train_data = full_data[:-int(test_size*len(full_data))]\n",
    "test_data = full_data[-int(test_size*len(full_data)):]\n",
    "\n",
    "\n",
    "\n",
    "for i in train_data:\n",
    "    train_set[i[-1]].append(i[:-1])\n",
    "\n",
    "    \n",
    "for i in test_data:\n",
    "    test_set[i[-1]].append(i[:-1])\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for group in test_set:\n",
    "    for data in test_set[group]:\n",
    "        vote = k_nearest_neighbors(train_set, data, k=5)\n",
    "        if group == vote:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "print('Accuracy:', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57ff9545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9642857142857143\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 31.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('breast-cancer-wisconsin.data')\n",
    "df.replace('?',-99999, inplace=True)\n",
    "df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "X = np.array(df.drop(columns=['class']))\n",
    "y = np.array(df['class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae4fba0",
   "metadata": {},
   "source": [
    "## The speed, per round of the Scikit-Learn version of KNN was 0.046 seconds, vs our 1.08 seconds, per classification. Thus, while we achieved identical results, we're significantly slower than Scikit-Learn. This is due to scikit learn having a default radius under which it works and also other things in its source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8969c7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "4 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 0.6\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 0.8\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 0.8\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 0.6\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 0.6\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "4 0.8\n",
      "4 0.8\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 0.6\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 1.0\n",
      "2 0.6\n",
      "2 1.0\n",
      "2 0.6\n",
      "2 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.6\n",
      "4 1.0\n",
      "4 1.0\n",
      "2 0.6\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "2 0.6\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "2 0.6\n",
      "2 0.6\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.6\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 0.8\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "2 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "2 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 0.8\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "4 1.0\n",
      "Accuracy: 0.967741935483871\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def k_nearest_neighbors(data, predict, k=3):\n",
    "    if len(data) >= k:\n",
    "        warnings.warn('K is set to a value less than total voting groups!')\n",
    "    distances = []\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict))\n",
    "            distances.append([euclidean_distance, group])\n",
    "\n",
    "    votes = [i[1] for i in sorted(distances)[:k]]\n",
    "    vote_result = Counter(votes).most_common(1)[0][0]\n",
    "    confidence = Counter(votes).most_common(1)[0][1] / k\n",
    "    print(vote_result, confidence)\n",
    "    return vote_result, confidence\n",
    "\n",
    "\n",
    "df = pd.read_csv('breast-cancer-wisconsin.data')\n",
    "df.replace('?',-99999, inplace=True)\n",
    "df.drop(columns=['id'], inplace=True)\n",
    "full_data = df.astype(float).values.tolist()\n",
    "random.shuffle(full_data)\n",
    "\n",
    "test_size = 0.4\n",
    "train_set = {2:[], 4:[]}\n",
    "test_set = {2:[], 4:[]}\n",
    "train_data = full_data[:-int(test_size*len(full_data))]\n",
    "test_data = full_data[-int(test_size*len(full_data)):]\n",
    "\n",
    "for i in train_data:\n",
    "    train_set[i[-1]].append(i[:-1])\n",
    "    \n",
    "for i in test_data:\n",
    "    test_set[i[-1]].append(i[:-1])\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for group in test_set:\n",
    "    for data in test_set[group]:\n",
    "        vote,confidence = k_nearest_neighbors(train_set, data, k=5)\n",
    "        if group == vote:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "print('Accuracy:', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a9d1583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.6\n",
      "0.6\n",
      "1.0\n",
      "0.8\n",
      "Accuracy: 0.982078853046595\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def k_nearest_neighbors(data, predict, k=3):\n",
    "    if len(data) >= k:\n",
    "        warnings.warn('K is set to a value less than total voting groups!')\n",
    "    distances = []\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict))\n",
    "            distances.append([euclidean_distance, group])\n",
    "\n",
    "    votes = [i[1] for i in sorted(distances)[:k]]\n",
    "    vote_result = Counter(votes).most_common(1)[0][0]\n",
    "    confidence = Counter(votes).most_common(1)[0][1] / k\n",
    "    return vote_result, confidence\n",
    "\n",
    "\n",
    "df = pd.read_csv('breast-cancer-wisconsin.data')\n",
    "df.replace('?',-99999, inplace=True)\n",
    "df.drop(columns=['id'], inplace=True)\n",
    "full_data = df.astype(float).values.tolist()\n",
    "random.shuffle(full_data)\n",
    "\n",
    "test_size = 0.4\n",
    "train_set = {2:[], 4:[]}\n",
    "test_set = {2:[], 4:[]}\n",
    "train_data = full_data[:-int(test_size*len(full_data))]\n",
    "test_data = full_data[-int(test_size*len(full_data)):]\n",
    "\n",
    "for i in train_data:\n",
    "    train_set[i[-1]].append(i[:-1])\n",
    "    \n",
    "for i in test_data:\n",
    "    test_set[i[-1]].append(i[:-1])\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for group in test_set:\n",
    "    for data in test_set[group]:\n",
    "        vote,confidence = k_nearest_neighbors(train_set, data, k=5)\n",
    "        if group == vote:\n",
    "            correct += 1\n",
    "        else :\n",
    "            print(confidence)\n",
    "        total += 1\n",
    "print('Accuracy:', correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c9cb47",
   "metadata": {},
   "source": [
    "<font color=\"blue\">\n",
    "\n",
    "## In learning algorithm, Confidence defines the probability of the event (or probability of input to fall in different classes). If a class has high probability then it has high confidence. Confidence value can be calculated for single input as well giving the meaning as how much the algorithm is confident for that class.\n",
    "\n",
    "## On the other hand, accuracy defines the skill of the learning algorithm to predict accurately. It defines the percentage of correct predictions made from all predictions.Such as when we predict places where only 0.6 probability is there or place where 1.0 probability is there(socho)\n",
    "</font>\n",
    "    \n",
    "## Jaise upar maan lo K=5 hai to agar paancho nearest points ek hi group se hai to confidence 1.0 hoga aur agar 4 ek group se to confidence 0.8 hoga\n",
    "\n",
    "## Accuracy is the measure of predictability ki hamne agar sahi se predict kar diya ki yaha par confidence 0.4 ya yaha pe 0.8 hai to wo model accurate\n",
    "\n",
    "## Upar hamare model ne sirf 5 confidences ko dhang se predict nahi kiya jiski wajah se hamari accuracy 0.982078853046595 hai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11afcfb",
   "metadata": {},
   "source": [
    "<font color=\"red\">\n",
    "\n",
    "# One more thing is at : https://youtu.be/r_D5TTV9-2c , from 12:00 minute onwards to 14:36, just 2 minutes of content which you could see at 2x speed\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
